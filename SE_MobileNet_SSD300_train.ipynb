{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0f42caf4a6c44d8c1ec29e74cd431d3e90f775b4a89b4957cc42fa68a41cd6730",
   "display_name": "Python 3.8.5 64-bit ('mypytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please install libjpeg-turbo and then jpeg4py \n",
    "# https://sourceforge.net/projects/libjpeg-turbo/\n",
    "# pip install jpeg4py\n",
    "# then install prefetch_generator by using pip: pip install prefetch_generator\n",
    "# before training please change the HOME directory location in the config file present at 'data/config.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# conda environments:\n#\nbase                     C:\\Users\\Anubhav\\anaconda3\nacii                     C:\\Users\\Anubhav\\anaconda3\\envs\\acii\namigos                   C:\\Users\\Anubhav\\anaconda3\\envs\\amigos\nideas                    C:\\Users\\Anubhav\\anaconda3\\envs\\ideas\nmypytorch             *  C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\nneuralcar                C:\\Users\\Anubhav\\anaconda3\\envs\\neuralcar\nprojectx                 C:\\Users\\Anubhav\\anaconda3\\envs\\projectx\npuzzle                   C:\\Users\\Anubhav\\anaconda3\\envs\\puzzle\n\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpeg4py as jpeg\n",
    "from PIL import Image\n",
    "\n",
    "# # img = Image.open(r'C:\\Users\\Anubhav\\data\\VOCdevkit\\VOC2007\\JPEGImages\\000001.jpg')\n",
    "# img = jpeg.JPEG(source=r'C:\\Users\\Anubhav\\data\\VOCdevkit\\VOC2007\\JPEGImages\\000001.jpg').decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd_mobilenet_se import build_ssd_mobilenet_se\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class DataLoaderX(data.DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_warmup = False\n",
    "args_backbone = 'mobilenet'\n",
    "args_from_scratch = True\n",
    "args_cuda = True\n",
    "args_save_folder = 'weights/'\n",
    "args_gamma = 0.1\n",
    "args_weight_decay = 5e-4\n",
    "args_momentum = 0.9\n",
    "args_lr = 1e-3\n",
    "args_num_workers = 2 # try -1\n",
    "args_start_iter = 0\n",
    "args_batch_size = 32\n",
    "args_dataset_root = VOC_ROOT\n",
    "args_dataset = 'VOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'C:/Users/Anubhav/Jupyter Projects/computer_vision [mypytorch]/ssd_mobv2/data/VOCdevkit/'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "VOC_ROOT # contains the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if args_cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    if not args_cuda:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists(args_save_folder):\n",
    "    os.mkdir(args_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'C:/Users/Anubhav/Jupyter Projects/computer_vision [mypytorch]/ssd_mobv2/'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_learning_rate(optimizer, steps, warmup_steps):\n",
    "    min_lr = args_lr / 100\n",
    "    slope = (args_lr - min_lr) / warmup_steps\n",
    "\n",
    "    lr = steps * slope + min_lr\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = args_lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:/Users/Anubhav/Jupyter Projects/computer_vision [mypytorch]/ssd_mobv2/\n",
      "C:/Users/Anubhav/Jupyter Projects/computer_vision [mypytorch]/ssd_mobv2/\n",
      "Initializing weights...\n",
      "SSDMobileNetSEV2(\n",
      "  (backbone): ModuleList(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): CELU(alpha=1.0, inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=16, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=16, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=24, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=24, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=24, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=24, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=24, out_features=1, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=1, out_features=24, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=48, out_features=3, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=3, out_features=48, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=48, out_features=3, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=3, out_features=48, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=48, out_features=3, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=3, out_features=48, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=48, out_features=3, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=3, out_features=48, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=72, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=72, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=72, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=72, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=432, bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=72, out_features=4, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=4, out_features=72, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=432, bias=False)\n",
      "          (1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(432, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=120, out_features=7, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=7, out_features=120, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=120, out_features=7, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=7, out_features=120, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=120, out_features=7, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=7, out_features=120, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=720, bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(720, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=240, out_features=15, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=15, out_features=240, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): L2Norm()\n",
      "  (extras): ModuleList(\n",
      "    (0): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(240, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual_SE(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): CELU(alpha=1.0, inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): SELayer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "            (3): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (top_down): ModuleList(\n",
      "    (0): Conv2d(72, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(240, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (final_features): ModuleList(\n",
      "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "extras: ModuleList(\n",
      "  (0): InvertedResidual_SE(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): Conv2d(240, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (1): ConvBNReLU(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): InvertedResidual_SE(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (1): ConvBNReLU(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual_SE(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (1): ConvBNReLU(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual_SE(\n",
      "    (conv): Sequential(\n",
      "      (0): ConvBNReLU(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (1): ConvBNReLU(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): CELU(alpha=1.0, inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loading the dataset...\n",
      "Training SSD on: VOC\n",
      "c:\\Users\\Anubhav\\Jupyter Projects\\computer_vision [mypytorch]\\ssd_mobv2\\ssd_mobilenet_se.py:35: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
      "<ipython-input-14-1926969fad54>:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(param)\n"
     ]
    }
   ],
   "source": [
    "''' config files contains  HOME path, COLORS, MEANS, voc config'''\n",
    "cfg = voc\n",
    "dataset = VOCDetection(root=args_dataset_root, transform=SSDAugmentation(cfg['min_dim'], MEANS))\n",
    "\n",
    "ssd_net = build_ssd_mobilenet_se('train', cfg)\n",
    "\n",
    "print('Initializing weights...')\n",
    "# initialize newly added layers' weights with xavier method\n",
    "ssd_net.extras.apply(weights_init)\n",
    "ssd_net.loc.apply(weights_init)\n",
    "ssd_net.conf.apply(weights_init)\n",
    "\n",
    "net = ssd_net\n",
    "print(net)\n",
    "print('extras:', net.extras)\n",
    "\n",
    "if args_cuda:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if args_cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=args_lr, momentum=args_momentum,\n",
    "                        weight_decay=args_weight_decay)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 100)\n",
    "criterion = MultiBoxLoss(cfg['num_classes'], 0.4, True, 0, True, 3, 0.5,\n",
    "                            False, args_cuda)\n",
    "\n",
    "net.train()\n",
    "# loss counters\n",
    "loc_loss = 0\n",
    "conf_loss = 0\n",
    "epoch = 0\n",
    "\n",
    "print('Loading the dataset...')\n",
    "\n",
    "epoch_size = len(dataset) // args_batch_size\n",
    "print('Training SSD on:', args_dataset)\n",
    "\n",
    "step_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoaderX(dataset, args_batch_size,\n",
    "                                num_workers=args_num_workers,\n",
    "                                shuffle=True, collate_fn=detection_collate,\n",
    "                                pin_memory=True)\n",
    "# create batch iterator\n",
    "batch_iterator = iter(data_loader)\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "timer: 436.5084 sec.\n",
      "iter 1000 || Loc loss: 0.0447 || Conf loss: 0.0353 || lr: 0.001000 timer: 416.2601 sec.\n",
      "iter 2000 || Loc loss: 0.0748 || Conf loss: 0.0663 || lr: 0.001000 timer: 413.6548 sec.\n",
      "iter 3000 || Loc loss: 0.0221 || Conf loss: 0.0203 || lr: 0.001000 timer: 417.4506 sec.\n",
      "iter 4000 || Loc loss: 0.0513 || Conf loss: 0.0512 || lr: 0.001000 timer: 428.5785 sec.\n",
      "iter 5000 || Loc loss: 0.0067 || Conf loss: 0.0066 || lr: 0.001000 Saving state, iter: 5000\n",
      "timer: 413.9170 sec.\n",
      "iter 6000 || Loc loss: 0.0346 || Conf loss: 0.0365 || lr: 0.001000 timer: 414.2126 sec.\n",
      "iter 7000 || Loc loss: 0.0597 || Conf loss: 0.0664 || lr: 0.001000 timer: 420.6989 sec.\n",
      "iter 8000 || Loc loss: 0.0196 || Conf loss: 0.0229 || lr: 0.001000 timer: 431.9799 sec.\n",
      "iter 9000 || Loc loss: 0.0442 || Conf loss: 0.0518 || lr: 0.001000 C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "timer: 521.7661 sec.\n",
      "iter 10000 || Loc loss: 0.0086 || Conf loss: 0.0103 || lr: 0.000854 Saving state, iter: 10000\n",
      "timer: 760.6689 sec.\n",
      "iter 11000 || Loc loss: 0.0326 || Conf loss: 0.0382 || lr: 0.000831 timer: 518.5209 sec.\n",
      "iter 12000 || Loc loss: 0.0525 || Conf loss: 0.0658 || lr: 0.000794 timer: 610.9929 sec.\n",
      "iter 13000 || Loc loss: 0.0200 || Conf loss: 0.0256 || lr: 0.000768 timer: 559.3273 sec.\n",
      "iter 14000 || Loc loss: 0.0397 || Conf loss: 0.0518 || lr: 0.000727 timer: 480.2357 sec.\n",
      "iter 15000 || Loc loss: 0.0100 || Conf loss: 0.0131 || lr: 0.000699 Saving state, iter: 15000\n",
      "timer: 568.4469 sec.\n",
      "iter 16000 || Loc loss: 0.0289 || Conf loss: 0.0383 || lr: 0.000655 timer: 450.9764 sec.\n",
      "iter 17000 || Loc loss: 0.0017 || Conf loss: 0.0020 || lr: 0.000624 timer: 503.9461 sec.\n",
      "iter 18000 || Loc loss: 0.0215 || Conf loss: 0.0282 || lr: 0.000578 timer: 406.3800 sec.\n",
      "iter 19000 || Loc loss: 0.0396 || Conf loss: 0.0525 || lr: 0.000547 timer: 467.2933 sec.\n",
      "iter 20000 || Loc loss: 0.0112 || Conf loss: 0.0157 || lr: 0.000500 Saving state, iter: 20000\n",
      "timer: 415.7499 sec.\n",
      "iter 21000 || Loc loss: 0.0295 || Conf loss: 0.0401 || lr: 0.000469 timer: 432.7317 sec.\n",
      "iter 22000 || Loc loss: 0.0037 || Conf loss: 0.0052 || lr: 0.000422 timer: 508.9107 sec.\n",
      "iter 23000 || Loc loss: 0.0204 || Conf loss: 0.0295 || lr: 0.000391 timer: 432.8260 sec.\n",
      "iter 24000 || Loc loss: 0.0370 || Conf loss: 0.0517 || lr: 0.000345 timer: 518.3700 sec.\n",
      "iter 25000 || Loc loss: 0.0135 || Conf loss: 0.0183 || lr: 0.000316 Saving state, iter: 25000\n",
      "timer: 461.9319 sec.\n",
      "iter 26000 || Loc loss: 0.0274 || Conf loss: 0.0400 || lr: 0.000273 timer: 515.2835 sec.\n",
      "iter 27000 || Loc loss: 0.0047 || Conf loss: 0.0077 || lr: 0.000245 timer: 427.0764 sec.\n",
      "iter 28000 || Loc loss: 0.0204 || Conf loss: 0.0304 || lr: 0.000206 timer: 545.2155 sec.\n",
      "iter 29000 || Loc loss: 0.0369 || Conf loss: 0.0535 || lr: 0.000181 timer: 619.4159 sec.\n",
      "iter 30000 || Loc loss: 0.0129 || Conf loss: 0.0196 || lr: 0.000146 Saving state, iter: 30000\n",
      "timer: 644.2787 sec.\n",
      "iter 31000 || Loc loss: 0.0274 || Conf loss: 0.0408 || lr: 0.000125 timer: 523.7172 sec.\n",
      "iter 32000 || Loc loss: 0.0074 || Conf loss: 0.0109 || lr: 0.000095 timer: 563.9774 sec.\n",
      "iter 33000 || Loc loss: 0.0208 || Conf loss: 0.0313 || lr: 0.000078 timer: 624.3695 sec.\n",
      "iter 34000 || Loc loss: 0.0011 || Conf loss: 0.0016 || lr: 0.000054 timer: 462.4595 sec.\n",
      "iter 35000 || Loc loss: 0.0157 || Conf loss: 0.0226 || lr: 0.000041 Saving state, iter: 35000\n",
      "timer: 685.8535 sec.\n",
      "iter 36000 || Loc loss: 0.0290 || Conf loss: 0.0441 || lr: 0.000024 timer: 598.6588 sec.\n",
      "iter 37000 || Loc loss: 0.0084 || Conf loss: 0.0134 || lr: 0.000016 timer: 637.8501 sec.\n",
      "iter 38000 || Loc loss: 0.0226 || Conf loss: 0.0342 || lr: 0.000006 timer: 638.5924 sec.\n",
      "iter 39000 || Loc loss: 0.0030 || Conf loss: 0.0044 || lr: 0.000002 timer: 560.8224 sec.\n",
      "iter 40000 || Loc loss: 0.0164 || Conf loss: 0.0251 || lr: 0.000000 Saving state, iter: 40000\n"
     ]
    }
   ],
   "source": [
    "hist_loss = []\n",
    "for iteration in range(args_start_iter, cfg['max_iter']):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    if iteration != 0 and (iteration % epoch_size == 0):\n",
    "        # reset epoch loss counters\n",
    "        hist_loss.append(running_loss)\n",
    "        loc_loss = 0\n",
    "        conf_loss = 0\n",
    "        epoch += 1\n",
    "\n",
    "    if args_warmup:\n",
    "        warmup_steps = 2000\n",
    "        if iteration < warmup_steps:\n",
    "            warmup_learning_rate(optimizer, iteration, warmup_steps)\n",
    "\n",
    "    cosine_period = int(cfg['lr_steps'][-1] / 100)\n",
    "    \n",
    "    if iteration > cfg['lr_steps'][0] and iteration % cosine_period == 0:\n",
    "        scheduler.step(iteration / cosine_period)\n",
    "\n",
    "    # load train data\n",
    "    try:\n",
    "        images, targets = next(batch_iterator)\n",
    "        # images, targets = data_loader\n",
    "    except StopIteration:\n",
    "        batch_iterator = iter(data_loader)\n",
    "        images, targets = next(batch_iterator)\n",
    "    except Exception as e:\n",
    "        print(\"Loading data exception:\", e)\n",
    "        print('ISSUEE :(')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if args_cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(ann.cuda()) for ann in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(ann) for ann in targets]\n",
    "\n",
    "    # forward\n",
    "    out = net(images)\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss_l, loss_c = criterion(out, targets)\n",
    "    loss = loss_l + loss_c\n",
    "    loss.backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(net.parameters(), max_norm=20, norm_type=2)\n",
    "    optimizer.step()\n",
    "    loc_loss += loss_l.item()\n",
    "    conf_loss += loss_c.item()\n",
    "\n",
    "    running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    \n",
    "    verbose_period = 1000\n",
    "    if iteration != 0 and iteration % verbose_period == 0:\n",
    "        print('timer: %.4f sec.' % (time.time() - t0))\n",
    "        t0 = time.time()\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print('iter ' + repr(iteration) + ' || Loc loss: %.4f || Conf loss: %.4f || lr: %.6f' % (loc_loss / verbose_period, conf_loss / verbose_period, lr), end=' ')\n",
    "        # loc_loss = 0\n",
    "        # conf_loss = 0\n",
    "\n",
    "    if iteration != 0 and iteration % 5000 == 0:\n",
    "        print('Saving state, iter:', iteration)\n",
    "        torch.save(net, 'weights/ssdSE300_VOC_' + repr(iteration) + \"__\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pth')\n",
    "torch.save(net, args_save_folder + '' + args_dataset + \"_SE_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'weights/'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "args_save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(range(len(hist_loss)), hist_loss, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Anubhav\\anaconda3\\envs\\mypytorch\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sns.lineplot(range(len(hist_loss)), hist_loss, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(hist_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('history_loss.pickle', 'wb') as f:\n",
    "        pickle.dump(hist_loss, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}